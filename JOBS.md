# Sistema de Jobs en Lote

Sistema completo para ejecutar trabajos de scraping en lote sin bloquear la interfaz de usuario.

## üìã Caracter√≠sticas

- ‚úÖ **Ejecuci√≥n as√≠ncrona**: Los jobs corren en background sin bloquear la UI
- ‚úÖ **Progreso en tiempo real**: Seguimiento del progreso paso a paso
- ‚úÖ **Estados detallados**: pending, running, completed, failed, cancelled
- ‚úÖ **Reintentos autom√°ticos**: Configurable por job (default: 2 reintentos)
- ‚úÖ **Comentarios**: Sistema de comentarios integrado para cada job
- ‚úÖ **Auto-refresh**: Actualizaci√≥n autom√°tica del estado cada 3-5 segundos
- ‚úÖ **Historial completo**: Cada paso guarda su resultado y posibles errores

## üèóÔ∏è Arquitectura

### Modelos de Datos

#### Job
```python
- id: Identificador √∫nico
- job_type: Tipo de trabajo (batch_scraping, single_scraping, etc.)
- name: Nombre descriptivo
- status: Estado actual (pending, running, completed, failed, cancelled)
- config: Configuraci√≥n JSON con par√°metros
- total_steps: Total de pasos a ejecutar
- completed_steps: Pasos completados exitosamente
- failed_steps: Pasos fallidos
- created_at, started_at, completed_at: Timestamps
```

#### JobStep
```python
- id: Identificador √∫nico
- job_id: Referencia al job padre
- step_number: N√∫mero de orden
- name: Nombre del paso (ej: "Scraping: example.com")
- status: Estado del paso
- result_data: JSON con resultados (ej: report_id)
- error_message: Mensaje de error si fall√≥
- started_at, completed_at: Timestamps
```

### Servicios

#### JobService (`app/services/job_service.py`)

**M√©todos principales:**

- `create_batch_scraping_job(domains, name, description)`: Crea un job para m√∫ltiples dominios
- `execute_job(job_id)`: Ejecuta el job de forma as√≠ncrona
- `start_job(job_id)`: Inicia el job en background
- `cancel_job(job_id)`: Cancela un job en ejecuci√≥n
- `get_job_status(job_id)`: Obtiene el estado actual
- `list_jobs(filters)`: Lista jobs con filtros opcionales

**Proceso de ejecuci√≥n:**

1. Se crea el job con estado `pending`
2. Se generan los pasos (uno por dominio)
3. `start_job()` crea una tarea asyncio en background
4. Cada paso se ejecuta secuencialmente:
   - Marca el paso como `running`
   - Ejecuta scraping con reintentos
   - Guarda resultado en BD
   - Marca como `completed` o `failed`
5. Al finalizar todos los pasos, marca el job como `completed`

## üîå API Endpoints

### Jobs

```
POST   /api/jobs/batch-scraping     - Crear y ejecutar job de scraping en lote
GET    /api/jobs                     - Listar jobs (con filtros)
GET    /api/jobs/{job_id}            - Obtener detalles de un job
POST   /api/jobs/{job_id}/cancel     - Cancelar un job
GET    /api/jobs/{job_id}/steps      - Obtener pasos de un job
GET    /api/jobs/stats/summary       - Estad√≠sticas generales
```

### Comentarios en Jobs

```
GET    /api/comments/job/{job_id}    - Obtener comentarios de un job
POST   /api/comments/job             - Crear comentario en un job
```

### P√°ginas Web

```
GET    /jobs                         - Lista de jobs
GET    /job/{job_id}                 - Detalle de un job espec√≠fico
```

## üíª Uso desde Frontend

### JavaScript (JobManager)

```javascript
// Crear un job
const domains = ['example.com', 'test.com', 'another.com'];
const job = await JobManager.createBatchScrapingJob(
    domains,
    'Mi Job de Scraping',
    'Descripci√≥n opcional'
);

// Redirigir al detalle
window.location.href = `/job/${job.id}`;

// Obtener estado de un job
const jobDetails = await JobManager.getJob(jobId);

// Iniciar polling autom√°tico
JobManager.startJobPolling(jobId, (job) => {
    console.log(`Progreso: ${job.progress_percentage}%`);
    console.log(`Completados: ${job.completed_steps}/${job.total_steps}`);
    
    if (job.status === 'completed') {
        console.log('Job finalizado!');
    }
}, 3000); // Actualiza cada 3 segundos

// Cancelar job
await JobManager.cancelJob(jobId);
```

### Desde Python

```python
from app.services.job_service import JobService
from app.database import SessionLocal

db = SessionLocal()

# Crear job
job = JobService.create_batch_scraping_job(
    db=db,
    domains=['example.com', 'test.com'],
    name='Mi Job',
    created_by='admin'
)

# Iniciar en background
JobService.start_job(job.id)

# Obtener estado
status = JobService.get_job_status(db, job.id)
print(f"Progreso: {status['progress_percentage']}%")
```

## üé® Interfaz de Usuario

### Lista de Jobs (`/jobs`)

- Visualizaci√≥n tipo card de todos los jobs
- Filtros por estado y tipo
- Estad√≠sticas en tiempo real (pendientes, en ejecuci√≥n, completados, fallidos)
- Bot√≥n para crear nuevo job
- Auto-refresh cada 5 segundos si hay jobs corriendo
- Barra de progreso visual para cada job

### Detalle de Job (`/job/{job_id}`)

- Informaci√≥n completa del job
- Lista de todos los pasos con su estado
- Barra de progreso general
- M√©tricas: total, completados, fallidos, pendientes
- Sistema de comentarios integrado
- Configuraci√≥n del job (JSON)
- Auto-refresh cada 3 segundos si est√° en ejecuci√≥n
- Bot√≥n para cancelar (solo si est√° running/pending)
- Links directos a los reportes generados

**Tabs disponibles:**
1. **Pasos**: Lista detallada de cada paso con iconos de estado
2. **Comentarios**: Sistema completo de comentarios
3. **Configuraci√≥n**: Vista JSON de la configuraci√≥n

## üöÄ Instalaci√≥n y Migraci√≥n

### 1. Migrar la base de datos

```bash
python migrate_jobs.py
```

Esto crear√° las tablas `jobs` y `job_steps` en la base de datos.

### 2. Verificar la instalaci√≥n

```bash
# Iniciar el servidor
uvicorn app.main:app --reload

# Acceder a:
# - http://localhost:8000/jobs (lista de jobs)
# - http://localhost:8000/docs (documentaci√≥n API)
```

## üìù Ejemplo de Uso Completo

### 1. Crear un Job desde la UI

1. Ir a `/jobs`
2. Click en "Nuevo Job"
3. Ingresar nombre y descripci√≥n (opcional)
4. Pegar lista de dominios (uno por l√≠nea)
5. Click en "Crear e Iniciar Job"
6. Ser√°s redirigido al detalle del job

### 2. Ver el progreso

La p√°gina de detalle se actualiza autom√°ticamente cada 3 segundos mostrando:
- Progreso general (%)
- Estado de cada dominio (pending, running, completed, failed)
- Links a los reportes generados
- Errores espec√≠ficos si alguno fall√≥

### 3. Agregar comentarios

En el tab "Comentarios" puedes agregar notas sobre el job:
- Observaciones
- Decisiones tomadas
- Pr√≥ximos pasos
- etc.

## üîß Configuraci√≥n

### Reintentos

Por defecto, cada dominio se reintenta 2 veces si falla. Puedes modificar esto en la configuraci√≥n del job:

```python
job = JobService.create_batch_scraping_job(
    db=db,
    domains=domains,
    name='Mi Job'
)

# Modificar configuraci√≥n antes de iniciar
job.config['max_retries'] = 3  # 3 reintentos
db.commit()

JobService.start_job(job.id)
```

### Intervalo entre dominios

Por defecto hay una pausa de 1 segundo entre cada dominio. Puedes modificar esto en `job_service.py`:

```python
# En _execute_batch_scraping()
await asyncio.sleep(1)  # Cambiar seg√∫n necesites
```

## üêõ Debugging

### Ver logs del servidor

```bash
# Los logs mostrar√°n:
# - Inicio y fin de cada job
# - Cada paso ejecutado
# - Errores detallados
```

### Verificar estado en base de datos

```sql
-- Ver todos los jobs
SELECT id, name, status, progress_percentage, total_steps, completed_steps, failed_steps 
FROM jobs 
ORDER BY created_at DESC;

-- Ver pasos de un job espec√≠fico
SELECT step_number, name, status, error_message 
FROM job_steps 
WHERE job_id = 1 
ORDER BY step_number;
```

## üéØ Casos de Uso

### 1. Analizar cartera de clientes
```
Crear job con 50 dominios de clientes
‚Üí Ejecuta en background sin bloquear
‚Üí Recibes notificaci√≥n al completar
‚Üí Revisas reportes generados
```

### 2. Monitoreo peri√≥dico
```
Crear job programado (futuro: cron)
‚Üí Re-escanea dominios importantes
‚Üí Compara con reportes anteriores
‚Üí Detecta cambios
```

### 3. Auditor√≠a de portfolio
```
Exportar lista de dominios
‚Üí Crear job masivo
‚Üí Analizar resultados
‚Üí Generar reporte consolidado
```

## üîÆ Futuras Mejoras

- [ ] Priorizaci√≥n de jobs (campo priority ya existe)
- [ ] Programaci√≥n de jobs (cron jobs)
- [ ] Notificaciones (email, webhook) al completar
- [ ] Exportaci√≥n de resultados (CSV, Excel, PDF)
- [ ] Jobs de comparaci√≥n entre reportes
- [ ] Limitar jobs concurrentes
- [ ] Dashboard de m√©tricas de jobs
- [ ] Webhook al completar cada paso
- [ ] API para integraci√≥n externa

## üìö Referencias

- **Modelos**: `app/models/job.py`
- **Servicio**: `app/services/job_service.py`
- **API Routes**: `app/routes/jobs.py`
- **Web Routes**: `app/routes/web.py`
- **Templates**: `templates/pages/jobs.html`, `templates/pages/job_detail.html`
- **JavaScript**: `static/js/components/jobManager.js`
